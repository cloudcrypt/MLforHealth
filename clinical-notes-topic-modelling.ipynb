{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Topic Modelling on Clinical Notes\n",
    "### Part a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import LdaMulticore\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.test.utils import datapath\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string, re\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"~/csc2548_ml4h/adult_notes.gz\", compression='gzip')\n",
    "dataset = dataset[~pd.isnull(dataset.chartext)]\n",
    "\n",
    "chartext = dataset.chartext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordList = stopwords.words(\"english\")\n",
    "\n",
    "def tokenize(s):\n",
    "    return [j for j in [re.sub(\"[\\W_]+\", '', i) for i in word_tokenize(s.lower())] \n",
    "            if j not in stopwordList and j != '']\n",
    "\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "corpus = pool.map(tokenize, chartext)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = mp.Pool(mp.cpu_count())\n",
    "bow_corpus = pool.map(dictionary.doc2bow, corpus)\n",
    "pool.close()\n",
    "pool.join()\n",
    "del chartext\n",
    "del corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: # of topics: 50, Coherence score: -0.35583472798066895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_lda(topics: int) -> LdaMulticore:\n",
    "    lda = LdaMulticore(bow_corpus, num_topics=topics, id2word=dictionary,\n",
    "                       workers=mp.cpu_count(), passes=5, per_word_topics=False, chunksize=1000)\n",
    "\n",
    "    cm = CoherenceModel(model=lda, corpus=bow_corpus, dictionary=dictionary, coherence=\"u_mass\")\n",
    "    score = cm.get_coherence()\n",
    "    \n",
    "    print(f\"LDA: # of topics: {topics}, Coherence score: {score}\\n\")\n",
    "    \n",
    "    lda.save(\"lda_\"+str(topics))\n",
    "    \n",
    "    return lda, score\n",
    "\n",
    "#lda_20, score_20 = generate_lda(20)\n",
    "lda_50, score_50 = generate_lda(50)\n",
    "#lda_100, score_100 = generate_lda(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA: # of topics: 20, Coherence score: -0.320345803714344\n",
    "\n",
    "LDA: # of topics: 50, Coherence score: -0.3141471647049764\n",
    "\n",
    "LDA: # of topics: 100, Coherence score: -0.3286962751461799"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word \"respiratory\" found in topics []\n",
      "\n",
      "Word \"vomiting\" found in topics []\n",
      "\n",
      "Word \"urine\" found in topics []\n",
      "\n",
      "Word \"pulse\" found in topics []\n"
     ]
    }
   ],
   "source": [
    "lda = lda_50\n",
    "\n",
    "lda.get_term_topics(dictionary.token2id[\"pulse\"])\n",
    "\n",
    "def examine_word(word: str, model: LdaMulticore):\n",
    "    topics = model.get_document_topics(dictionary.doc2bow([word]), per_word_topics=True)[1][0][1]\n",
    "    print(f\"\\nWord \\\"{word}\\\" found in topics {topics}\")\n",
    "    for topic in topics:\n",
    "        print(f\"Topic {topic}:\")\n",
    "        print(model.show_topic(topic))\n",
    "    \n",
    "examine_word(\"respiratory\", lda)\n",
    "examine_word(\"vomiting\", lda)\n",
    "examine_word(\"urine\", lda)\n",
    "examine_word(\"pulse\", lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(658, 1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "([(0, 0.02),\n",
       "  (1, 0.02),\n",
       "  (2, 0.02),\n",
       "  (3, 0.02),\n",
       "  (4, 0.02),\n",
       "  (5, 0.02),\n",
       "  (6, 0.02),\n",
       "  (7, 0.02),\n",
       "  (8, 0.02),\n",
       "  (9, 0.02),\n",
       "  (10, 0.02),\n",
       "  (11, 0.02),\n",
       "  (12, 0.02),\n",
       "  (13, 0.02),\n",
       "  (14, 0.02),\n",
       "  (15, 0.02),\n",
       "  (16, 0.02),\n",
       "  (17, 0.02),\n",
       "  (18, 0.02),\n",
       "  (19, 0.02),\n",
       "  (20, 0.02),\n",
       "  (21, 0.02),\n",
       "  (22, 0.02),\n",
       "  (23, 0.02),\n",
       "  (24, 0.02),\n",
       "  (25, 0.02),\n",
       "  (26, 0.02),\n",
       "  (27, 0.02),\n",
       "  (28, 0.02),\n",
       "  (29, 0.02),\n",
       "  (30, 0.02),\n",
       "  (31, 0.02),\n",
       "  (32, 0.02),\n",
       "  (33, 0.02),\n",
       "  (34, 0.02),\n",
       "  (35, 0.02),\n",
       "  (36, 0.02),\n",
       "  (37, 0.02),\n",
       "  (38, 0.02),\n",
       "  (39, 0.02),\n",
       "  (40, 0.02),\n",
       "  (41, 0.02),\n",
       "  (42, 0.02),\n",
       "  (43, 0.02),\n",
       "  (44, 0.02),\n",
       "  (45, 0.02),\n",
       "  (46, 0.02),\n",
       "  (47, 0.02),\n",
       "  (48, 0.02),\n",
       "  (49, 0.02)],\n",
       " [(658, [])],\n",
       " [(658, [])])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"respiratory\"\n",
    "dictionary.doc2bow([word])\n",
    "lda_50.get_document_topics(dictionary.doc2bow([word]), per_word_topics=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
